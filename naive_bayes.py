# -*- coding: utf-8 -*-
"""naive_bayes

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17PwWg7VCVC15ur93EXZnvE7VnwxyQ3Ya
"""

import pandas as pd

data = pd.read_csv("income.csv")

factors = data[["age","education-num","capital-gain","capital-loss","hours-per-week"]]
outcome = data["income"]

from sklearn.model_selection import train_test_split

f_train , f_test , o_train , o_test = train_test_split( factors , outcome , random_state = 45 , test_size = 0.3)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
f_train = ss.fit_transform(f_train)
f_test = ss.fit_transform(f_test)

print(f_test)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(f_train , o_train)
opredict = lr.predict(f_test)
from sklearn.metrics import accuracy_score

test = accuracy_score( o_test , opredict)
print(test)

from sklearn.naive_bayes import GaussianNB

gb = GaussianNB()

gb.fit(f_train , o_train)
opredict = gb.predict(f_test)
test = accuracy_score( o_test , opredict)
print(test)

data1 = pd.read_csv("diabetes1.csv")

factors1 = data1[["glucose","bloodpressure"]]
outcome1 = data1["diabetes"]

f_train1 , f_test1 , o_train1 , o_test1 = train_test_split( factors1 , outcome1 , random_state = 10 , test_size = 0.25)

f_train1 = ss.fit_transform(f_train1)
f_test1 = ss.fit_transform(f_test1)

gb.fit(f_train1 , o_train1)
predict = gb.predict(f_test1)

accuracy = accuracy_score(o_test1 , predict)
print(accuracy*100)

lr.fit(f_train1 , o_train1)
predict = lr.predict(f_test1)

accuracy = accuracy_score(o_test1 , predict)
print(accuracy*100)